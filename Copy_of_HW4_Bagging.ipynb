{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marianna718/C-beginner/blob/master/Copy_of_HW4_Bagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeByN5a5Y4gd"
      },
      "source": [
        "The deadline for this homework is on **27.25.2022 15:49** (right before the practice session). After completing the exercises, you should\n",
        "\n",
        "1. Download this file into your computer (`File` $\\to$ `Download .ipynb`)\n",
        "\n",
        "2. Download the python files (`.py`) (*if there are any attached to the homework that you need to complete*). \n",
        "\n",
        "3. Compress the above files (`.zip` `.rar`) and name the compressed file in the following way *HWx_NameSurname* (for example `HW4_AnunAzganun.zip`)\n",
        "\n",
        "4. Send the compressed file to this email address `fast.1991.ml@gmail.com` with subject **ML4**\n",
        "\n",
        "**Note**\n",
        "\n",
        "* if you do not follow any of the above conditions, your homework will not be graded.\n",
        "\n",
        "* you do not need to send any dataset files or helper scripts that I provide with your homework (since I already have them).\n",
        "\n",
        "* you need to write the code for the exercises yourself; you can use ``built-in functions``, ``numpy``, ``pandas``\n",
        "and ``matplotlib``. Use of other libraries or packages (e.g., scikit-learn) will result in points deducted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLDsaF5obCP0"
      },
      "source": [
        "# Mounting Google Drive\n",
        "\n",
        "1. Create a folder named ``ML`` in your drive\n",
        "\n",
        "2. Upload the compressed file ``hw4.zip`` into that folder\n",
        "\n",
        "3. Run the below code snippet and follow the instructions to give access to Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SUE2oiKVb1FQ",
        "outputId": "504e80ca-c6d5-47ea-dec0-7288346a42d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTBAkQWge9pP"
      },
      "source": [
        "4. We will change our current directory, so that it is easier to import the necessary files from our drive. To do so, just run the below code cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aogm6VrzcWm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84c478a-7c45-4d35-f255-bced18c7a6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/Hmw4\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/ML/Hmw4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mysjIuuAfRPM"
      },
      "source": [
        "5. Now that we are in the desired location, we can unzip the compressed file. \n",
        "\n",
        "  **Note that this step needs to be done only once**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GI8jHqGwfQMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec680e5b-0e65-41d8-9e09-1da78dce3f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  hw4.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of hw4.zip or\n",
            "        hw4.zip.zip, and cannot find hw4.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!unzip hw4.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPcIuODgftAX"
      },
      "source": [
        "6. Run the below code snippet to import all the necessary libraries, as well as the module(``bagging.py``), which you will fill in soon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mQ1GWOx32xBW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid') # Plot style\n",
        "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from bagging import Bagging, RandomForest\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhgBAK2NRTdS"
      },
      "source": [
        "In this homework we will use a variation of the digits data. You can find the [here](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncE5FTjvRsjY",
        "outputId": "d34c5434-78f8-4e0e-ea0b-83adc22992a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (360, 64)\n",
            "y shape: (360,)\n",
            "<class 'sklearn.utils.Bunch'>\n"
          ]
        }
      ],
      "source": [
        "data = datasets.load_digits(n_class=2) \n",
        "X = data.data\n",
        "y = data.target\n",
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6jRQjyER2Gq"
      },
      "source": [
        "We will set a test set aside for final evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tPSp5eTnRstH"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=20,\n",
        "                                                    random_state=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJaqCPqvRsyi",
        "outputId": "f2923079-65a0-4038-df5e-710c3fa02546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (340,)\n",
            "Test: (20,)\n"
          ]
        }
      ],
      "source": [
        "print('Train:', y_train.shape)\n",
        "print('Test:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN9tCnNNSALV"
      },
      "source": [
        "As you may have noticed we have a small set of training data, which means that we should not put aside additional data for validation, instead we will use cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tzI5e-oJJlr"
      },
      "source": [
        "# Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEj62iV1JNZS"
      },
      "source": [
        "Until now we have evaluated our models based on their score on a hold-out test set. In this homework, you will need to implement your own cross-validation method inside the function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FsVNlJTqJJBf"
      },
      "outputs": [],
      "source": [
        "def do_cross_validation(model, X_train, y_train, k, random_state):\n",
        "  \"\"\"\n",
        "  Computes the cross-validation accuracy score\n",
        "  :param model: model object that has fit and predict methods\n",
        "  :param X_train: nd array of size (nr_data_points, nr_features)\n",
        "  :param y_train: nd array of size (nr_data_points, )\n",
        "  :param k: int for the number of folds (usually k={1,5,10})\n",
        "  :param random_state: int for fixing the randomness in order to reproduce\n",
        "                       the same results\n",
        "  :returns: float of the cross-validation score\n",
        "  \"\"\"\n",
        "  # Hints: you need to\n",
        "  # 1. shuffle your data\n",
        "  # 2. split your data into k disjoint parts\n",
        "  # 3. for each of the k steps:\n",
        "  #       select k-1 parts for training \n",
        "  #      (you may need to concatenate your data)\n",
        "  #      and use the other part for testing\n",
        "  #      save the accuracy score (use sklearn's function) on the test set\n",
        "  #      in some data structure (e.g. list)\n",
        "  # 4. when you do the above procedure, you will have k accuracy scores\n",
        "  # your function should return the average of those numbers\n",
        "\n",
        "  nr_data_points = X_train.shape[0]\n",
        "  np.random.seed(random_state)\n",
        "  indices = np.arange(nr_data_points)\n",
        "  np.random.shuffle(indices) #xarnum enq indexnery\n",
        "\n",
        "  # YOUR CODE HERE  \n",
        "\n",
        "  nr_data_in_each_fold = nr_data_points // k  # voroshum enq te inch heravorutyan vra en linelu shertery\n",
        "  fold_indeices = np.arange(0,nr_data_points+1, nr_data_in_each_fold) #arandznacnum enq bajanman keteri indexnery , xmberi\n",
        "  scores = []\n",
        "  for k_ in range(k):  #amen sherti hamar validation anelu hamar \n",
        "    st = fold_indeices[k_]    #sherti sksvelu indexy\n",
        "    end = fold_indeices[k_ +1]  #sherti avartvelu indexy \n",
        "    test_indices = indices[st:end] #vercnum enq hamapatasxan sherti tarery, aysinqn mer x-eri indexnery \n",
        "    x_te = X_train[test_indices, :] #arandznacnum enq pujur testi masy \n",
        "    y_te = y_train[test_indices]  #arandznacnum enq dran hamapatasxan pujur y-neri masy\n",
        "    train_indeces = np.array(list(set(indices) - set(test_indices))) #arandnacnum enq traini indexnery\n",
        "    x_tr = X_train[train_indeces, :] #traini hamapatasxan x-ery\n",
        "    y_tr = y_train[train_indeces]  #traini y-nery\n",
        "    model.fit(x_tr, y_tr)   #modely traain enq anum mer traini vra\n",
        "    preds = model.predict(x_te)  #predict enq anum pujur testi hamar\n",
        "    scores.apprend(accuracy_score(y_te, preds)) #scorei mej el de havaqum enq vor heto mean hashvenq accuracyneri\n",
        "  return np.mean(scores)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bStU8M4MJNgQ"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahkg4obBJNuH"
      },
      "source": [
        "Complete the incomplete parts in `bagging.py` script. For the base_estimator we will use the DecisionTreeClassifier from sklearn, but you can also use your own implementation if you want to.\n",
        "\n",
        "In order to check your implementation, make sure that your Bagging model is able to learn from data (even overfit on it) and result in almost perfect classification on this simple task. You should get above 99% CV accuracy with 20 models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6qFA3YnUJN0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "8713eff5-5f5b-4101-fb9a-b23340acc671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model Training: 100% [-----------------------------------------] Time:  0:00:00\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-cf1962998e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV accuracy is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-af02bd7b443f>\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(model, X_train, y_train, k, random_state)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#modely traain enq anum mer traini vra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predict enq anum pujur testi hamar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapprend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#scorei mej el de havaqum enq vor heto mean hashvenq accuracyneri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'apprend'"
          ]
        }
      ],
      "source": [
        "model = Bagging(base_estimator=DecisionTreeClassifier, nr_estimators=20)\n",
        "cv_acc = do_cross_validation(model, X_train, y_train, k=10, random_state=0)\n",
        "print('CV accuracy is:', cv_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PNNr0ravH3_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "l = np.array([[1,2,1,1],[5,5,1,8],[4,3,2,7]])\n",
        "l.reshape(2, -1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRqF0-22yMqf",
        "outputId": "c2360416-07e1-4100-b3c4-28c458828703"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 1, 1, 5, 5],\n",
              "       [1, 8, 4, 3, 2, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZtmyGlRJN5S"
      },
      "source": [
        "Choose the best value for the number of models in the ensemble based on 10-fold cross-validation (keep the ``random_seed=0``). Plot a figure to show what happens with the CV accuracy when we change the number of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xiPFZTUZJN-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8973d53f-298e-4231-a82e-a638d1e657fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d4528268c525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mcv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Bagging' is not defined"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "l = np.arange(1,21,2)\n",
        "scores = []\n",
        "\n",
        "for k in l:\n",
        "  model = Bagging(base_estimator = DecisionTreeClassifier, nr_estimator = k)\n",
        "  cv_acc = do_cross_validation(model, X_train,y_train, k = 10, random_state =0)\n",
        "  scores.append(cv_acc)\n",
        "print(l[np.argmax(scores)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjXfTgM6IMKI"
      },
      "source": [
        "**Question** Based on your experiments, what is the best value for the number of models in the ensemble?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HgWs8FQRF3B"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bY6XPqEd_hL"
      },
      "source": [
        "\n",
        "Use the best value of the number of models and train the final model on the whole train dataset and test the model on the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3vnRUuO_d_ud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "eed42b76-b39e-4c85-dbed-f5a45c9dd41c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-285c2d4ecedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpreds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Bagging train accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Bagging' is not defined"
          ]
        }
      ],
      "source": [
        "model1 = Bagging(base_estimator = DecisionTreeClassifier, nr_estimators = 3) # YOUR CODE HERE\n",
        "model1.fit(X_train, y_train)\n",
        "preds1 = model1.predict(X_train)\n",
        "preds2 = model1.predict(X_test)\n",
        "print('Bagging train accuracy:', accuracy_score(y_train, preds1))\n",
        "print('Bagging test accuracy:', accuracy_score(y_test, preds2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8bXyfc4eQYc"
      },
      "source": [
        "**Question:** What results did you get? How well did the algorithm learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxR7ZDtFglYZ"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy-1rcKsJOEb"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "Now we will check the implementation for the Random Forest classifier. Make sure you get above 99% CV accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJD79Iq9JOKX"
      },
      "outputs": [],
      "source": [
        "model = RandomForest(10)\n",
        "cv_acc = do_cross_validation(model, X_train, y_train, k=10, random_state=0)\n",
        "print('CV accuracy is:', cv_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn515Qu6b-nJ"
      },
      "source": [
        "Again, choose the best value for the number of models in the ensemble based on 10-fold cross-validation (keep the ``random_seed=0``). Plot a figure to show what happens with the CV accuracy when we change the number of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMFVkqNCg7tV"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0RuwHRCh09e"
      },
      "source": [
        "**Question** Based on your experiments, what is the best value for the number of models in the ensemble?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jQ9RXjAh09f"
      },
      "source": [
        "**Answer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anAqSZsUh09f"
      },
      "source": [
        "Use the best value of the number of models and train the final model on the whole train dataset and test the model on the train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZeraQNDhJ19"
      },
      "outputs": [],
      "source": [
        "model2 = # YOUR CODE HERE\n",
        "model2.fit(X_train, y_train)\n",
        "preds_rf1 = model2.predict(X_train)\n",
        "preds_rf2 = model2.predict(X_test)\n",
        "print('Bagging train accuracy:', accuracy_score(y_train, preds_rf1))\n",
        "print('Bagging test accuracy:', accuracy_score(y_test, preds_rf2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxfw8Tkzh5-G"
      },
      "source": [
        "**Question:** What results did you get? How well did the algorithm learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be12WF60h5-H"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoMhwmf2b-8m"
      },
      "source": [
        "# Out-of-bag Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgcTeSCKu3t8"
      },
      "source": [
        "Now choose the best number of models in the ensemble based on the OOB score, for both of the algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKjHV7LIcB2h"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4SxTGJtdSrZ"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPBD4d0ivKJZ"
      },
      "source": [
        "**Question:** Are the numbers (of the models) the same as with the cross-validation (CV) method? Is the overall trend of the both scores (OOB vs CV) the same when changing the number of models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmpA0hzpvJ8a"
      },
      "source": [
        "**Answer:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNTbeD0hdSwa"
      },
      "source": [
        "**Question:** In this homework, we have not compared the results of our implementation with that of sklearn's. Can you guess why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-L4ZODpdS3b"
      },
      "source": [
        "**Answer:**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of HW4_Bagging.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}